defaults:
  - model: multitask_model
  - datamodule: multitask
  - loop: multitask_loop

gpus: 1
num_workers: 8
random_seed: 1590258941

training:
  epochs: 100
  batch_size: 32
  accumulate_batches: 0
  precision: 16
  # checkpointing
  save_ckpts: 10
  monitor: val/loss
  mode: min
  patience: 5

testing:
  batch_size: ${training.batch_size}

logger:
  _target_: logger.loggers.WandbMinMaxLogger
log_gradients: False

hydra:
  run:
    dir: ./outputs/single/${model._target_}/${now:%Y-%m-%d}/${now:%H-%M-%S}

  sweep:
    dir: outputs/sweep/${now:%Y-%m-%d}/${now:%H-%M-%S}
    # subdir: lr:${loop.optimizer.lr}