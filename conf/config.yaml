defaults:
  - model: multitask_model
  - datamodule: multitask
  - loop: multitask_loop

gpus: 1
num_workers: 4
random_seed: 1590258941

training:
  epochs: 100
  warmup_steps: 10000
  batch_size: 32
  accumulate_batches: 1
  precision: 32
  # checkpointing
  save_ckpts: 10
  monitor: val/trec_map/trec2019
  mode: max
  patience: 5

testing:
  batch_size: ${training.batch_size}

logger:
  project: mtl-ranking
  _target_: logger.loggers.WandbMinMaxLogger
log_gradients: False

hydra:
  run:
    dir: outputs/single/${model.body._target_}/${loop.loss._target_}/${now:%Y-%m-%d}/${now:%H-%M-%S}

  sweep:
    dir: outputs/sweep/${model.body._target_}/${loop.loss._target_}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    # subdir: lr:${loop.optimizer.lr}